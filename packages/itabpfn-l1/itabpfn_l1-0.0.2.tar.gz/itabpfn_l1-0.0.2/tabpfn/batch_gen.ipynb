{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.priors import *\n",
    "from tabpfn.model_configs import get_prior_config, create_configspace_from_hierarchical, sample_differentiable, evaluate_hypers\n",
    "from tabpfn.priors.mlp import get_batch\n",
    "from tabpfn.scripts import model_builder\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from scripts.differentiable_pfn_evaluation import eval_model_range\n",
    "# No string\n",
    "from tabpfn.scripts.model_builder import get_model, get_default_spec, save_model, load_model\n",
    "from tabpfn.scripts.transformer_prediction_interface import transformer_predict, get_params_from_config, load_model_workflow\n",
    "\n",
    "from tabpfn.scripts.model_configs import *\n",
    "\n",
    "from tabpfn.datasets import load_openml_list, open_cc_dids, open_cc_valid_dids\n",
    "from tabpfn.priors.utils import plot_prior, plot_features\n",
    "from tabpfn.priors.utils import uniform_int_sampler_f\n",
    "\n",
    "from tabpfn.scripts.tabular_metrics import calculate_score_per_method, calculate_score\n",
    "# No string\n",
    "#from scripts.tabular_evaluation import evaluate\n",
    "\n",
    "from tabpfn.priors.differentiable_prior import DifferentiableHyperparameterList, draw_random_style, merge_style_with_info, replace_differentiable_distributions\n",
    "from tabpfn.scripts import tabular_metrics\n",
    "from tabpfn.notebook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.00011384360782765453, 'dropout': 0.0, 'emsize': 256, 'batch_size': 64, 'nlayers': 12, 'num_features': 100, 'nhead': 4, 'nhid_factor': 2, 'bptt': 50, 'eval_positions': None, 'seq_len_used': 50, 'sampling': 'mixed', 'epochs': 80, 'num_steps': 100, 'verbose': False, 'mix_activations': False, 'pre_sample_causes': True, 'multiclass_type': 'value', 'nan_prob_unknown_reason_reason_prior': 0.5, 'categorical_feature_p': 0.1, 'nan_prob_no_reason': 0.0, 'nan_prob_unknown_reason': 0.0, 'nan_prob_a_reason': 0.0, 'max_num_classes': 2, 'num_classes': 2, 'noise_type': 'Gaussian', 'balanced': True, 'normalize_to_ranking': False, 'set_value_to_nan': 0.2, 'normalize_by_used_features': True, 'num_features_used': {'uniform_int_sampler_f(3,max_features)': <function <lambda>.<locals>.<lambda> at 0x7f9790314160>}, 'num_categorical_features_sampler_a': -1.0, 'prior_bag_exp_weights_1': 4.139472938986653, 'num_layers': <function DifferentiableHyperparameter.__init__.<locals>.make_gamma.<locals>.<lambda> at 0x7f97903141f0>, 'prior_mlp_hidden_dim': <function DifferentiableHyperparameter.__init__.<locals>.make_gamma.<locals>.<lambda> at 0x7f9780080280>, 'prior_mlp_dropout_prob': <function DifferentiableHyperparameter.__init__.<locals>.make_beta.<locals>.<lambda> at 0x7f97800805e0>, 'noise_std': <function DifferentiableHyperparameter.__init__.<locals>.make_trunc_norm.<locals>.<lambda> at 0x7f9780080940>, 'init_std': <function DifferentiableHyperparameter.__init__.<locals>.make_trunc_norm.<locals>.<lambda> at 0x7f9780080ca0>, 'num_causes': <function DifferentiableHyperparameter.__init__.<locals>.make_gamma.<locals>.<lambda> at 0x7f9780085040>, 'is_causal': True, 'pre_sample_weights': False, 'y_is_effect': False, 'prior_mlp_activations': <function DifferentiableHyperparameter.__init__.<locals>.make_choice.<locals>.<lambda> at 0x7f9780085ee0>, 'block_wise_dropout': False, 'sort_features': False, 'in_clique': True, 'outputscale': <function DifferentiableHyperparameter.__init__.<locals>.make_trunc_norm.<locals>.<lambda> at 0x7f9780085f70>, 'lengthscale': <function DifferentiableHyperparameter.__init__.<locals>.make_trunc_norm.<locals>.<lambda> at 0x7f978007a9d0>, 'noise': 1e-05, 'output_multiclass_ordered_p': 0.45198989392503136}\n"
     ]
    }
   ],
   "source": [
    "# Setting up the configuration for the simulation of batch\n",
    "config = get_prior_config(\"causal\")\n",
    "\n",
    "#hyper1 = model_builder.get_mlp_prior_hyperparameters(config)\n",
    "hyper1 = evaluate_hypers(config, sample_diff_hps=True)\n",
    "hyper = sample_differentiable(hyper1)\n",
    "\n",
    "print(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': lr, Type: UniformFloat, Range: [0.0001, 0.00015], Default: 0.0001224745, on log-scale, 'dropout': dropout, Type: Categorical, Choices: {0.0}, Default: 0.0, 'emsize': emsize, Type: Categorical, Choices: {256}, Default: 256, 'batch_size': batch_size, Type: Categorical, Choices: {64, 128}, Default: 64, 'nlayers': nlayers, Type: Categorical, Choices: {12}, Default: 12, 'num_features': 100, 'nhead': nhead, Type: Categorical, Choices: {4}, Default: 4, 'nhid_factor': 2, 'bptt': 50, 'eval_positions': None, 'seq_len_used': 50, 'sampling': 'normal', 'epochs': 80, 'num_steps': 100, 'verbose': False, 'mix_activations': False, 'pre_sample_causes': True, 'multiclass_type': 'rank', 'nan_prob_unknown_reason_reason_prior': nan_prob_unknown_reason_reason_prior, Type: Categorical, Choices: {0.5}, Default: 0.5, 'categorical_feature_p': categorical_feature_p, Type: Categorical, Choices: {0.0, 0.1, 0.2}, Default: 0.0, 'nan_prob_no_reason': nan_prob_no_reason, Type: Categorical, Choices: {0.0, 0.1}, Default: 0.0, 'nan_prob_unknown_reason': nan_prob_unknown_reason, Type: Categorical, Choices: {0.0}, Default: 0.0, 'nan_prob_a_reason': nan_prob_a_reason, Type: Categorical, Choices: {0.0}, Default: 0.0, 'max_num_classes': 2, 'num_classes': 2, 'noise_type': noise_type, Type: Categorical, Choices: {Gaussian}, Default: Gaussian, 'balanced': True, 'normalize_to_ranking': normalize_to_ranking, Type: Categorical, Choices: {False}, Default: False, 'set_value_to_nan': set_value_to_nan, Type: Categorical, Choices: {0.5, 0.2, 0.0}, Default: 0.5, 'normalize_by_used_features': True, 'num_features_used': {'uniform_int_sampler_f(3,max_features)': <function <lambda>.<locals>.<lambda> at 0x7f8e62fe7af0>}, 'num_categorical_features_sampler_a': -1.0, 'differentiable_hyperparameters': {'prior_bag_exp_weights_1': {'distribution': 'uniform', 'min': 2.0, 'max': 10.0}, 'num_layers': {'distribution': 'meta_gamma', 'max_alpha': 2, 'max_scale': 3, 'round': True, 'lower_bound': 2}, 'prior_mlp_hidden_dim': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 4}, 'prior_mlp_dropout_prob': {'distribution': 'meta_beta', 'scale': 0.6, 'min': 0.1, 'max': 5.0}, 'noise_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 0.3, 'min_mean': 0.0001, 'round': False, 'lower_bound': 0.0}, 'init_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 0.01, 'round': False, 'lower_bound': 0.0}, 'num_causes': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 7, 'round': True, 'lower_bound': 2}, 'is_causal': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'pre_sample_weights': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'y_is_effect': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'sampling': {'distribution': 'meta_choice', 'choice_values': ['normal', 'mixed']}, 'prior_mlp_activations': {'distribution': 'meta_choice_mixed', 'choice_values': [<class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.ReLU'>]}, 'block_wise_dropout': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'sort_features': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'in_clique': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'outputscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'noise': {'distribution': 'meta_choice', 'choice_values': [1e-05, 0.0001, 0.01]}, 'output_multiclass_ordered_p': {'distribution': 'uniform', 'min': 0.0, 'max': 0.5}, 'multiclass_type': {'distribution': 'meta_choice', 'choice_values': ['value', 'rank']}}}\n",
      "{'lr': lr, Type: UniformFloat, Range: [0.0001, 0.00015], Default: 0.0001224745, on log-scale, 'dropout': dropout, Type: Categorical, Choices: {0.0}, Default: 0.0, 'emsize': emsize, Type: Categorical, Choices: {256}, Default: 256, 'batch_size': batch_size, Type: Categorical, Choices: {64, 128}, Default: 64, 'nlayers': nlayers, Type: Categorical, Choices: {12}, Default: 12, 'num_features': 100, 'nhead': nhead, Type: Categorical, Choices: {4}, Default: 4, 'nhid_factor': 2, 'bptt': 50, 'eval_positions': None, 'seq_len_used': 50, 'sampling': 'mixed', 'epochs': 80, 'num_steps': 100, 'verbose': False, 'mix_activations': False, 'pre_sample_causes': True, 'multiclass_type': 'rank', 'nan_prob_unknown_reason_reason_prior': nan_prob_unknown_reason_reason_prior, Type: Categorical, Choices: {0.5}, Default: 0.5, 'categorical_feature_p': categorical_feature_p, Type: Categorical, Choices: {0.0, 0.1, 0.2}, Default: 0.0, 'nan_prob_no_reason': nan_prob_no_reason, Type: Categorical, Choices: {0.0, 0.1}, Default: 0.0, 'nan_prob_unknown_reason': nan_prob_unknown_reason, Type: Categorical, Choices: {0.0}, Default: 0.0, 'nan_prob_a_reason': nan_prob_a_reason, Type: Categorical, Choices: {0.0}, Default: 0.0, 'max_num_classes': 2, 'num_classes': 2, 'noise_type': noise_type, Type: Categorical, Choices: {Gaussian}, Default: Gaussian, 'balanced': True, 'normalize_to_ranking': normalize_to_ranking, Type: Categorical, Choices: {False}, Default: False, 'set_value_to_nan': set_value_to_nan, Type: Categorical, Choices: {0.5, 0.2, 0.0}, Default: 0.5, 'normalize_by_used_features': True, 'num_features_used': {'uniform_int_sampler_f(3,max_features)': <function <lambda>.<locals>.<lambda> at 0x7f8e80d56b80>}, 'num_categorical_features_sampler_a': -1.0, 'prior_bag_exp_weights_1': 4.1482181602655155, 'num_layers': <function DifferentiableHyperparameter.__init__.<locals>.make_gamma.<locals>.<lambda> at 0x7f8e511b5c10>, 'prior_mlp_hidden_dim': <function DifferentiableHyperparameter.__init__.<locals>.make_gamma.<locals>.<lambda> at 0x7f8e80d39940>, 'prior_mlp_dropout_prob': <function DifferentiableHyperparameter.__init__.<locals>.make_beta.<locals>.<lambda> at 0x7f8e80d39b80>, 'noise_std': <function DifferentiableHyperparameter.__init__.<locals>.make_trunc_norm.<locals>.<lambda> at 0x7f8e62fd71f0>, 'init_std': <function DifferentiableHyperparameter.__init__.<locals>.make_trunc_norm.<locals>.<lambda> at 0x7f8e62fd7790>, 'num_causes': <function DifferentiableHyperparameter.__init__.<locals>.make_gamma.<locals>.<lambda> at 0x7f8e5117baf0>, 'is_causal': False, 'pre_sample_weights': False, 'y_is_effect': True, 'prior_mlp_activations': <function DifferentiableHyperparameter.__init__.<locals>.make_choice.<locals>.<lambda> at 0x7f8e62fe71f0>, 'block_wise_dropout': True, 'sort_features': True, 'in_clique': True, 'outputscale': <function DifferentiableHyperparameter.__init__.<locals>.make_trunc_norm.<locals>.<lambda> at 0x7f8e62fe7280>, 'lengthscale': <function DifferentiableHyperparameter.__init__.<locals>.make_trunc_norm.<locals>.<lambda> at 0x7f8e62fee280>, 'noise': 1e-05, 'output_multiclass_ordered_p': 0.17591953477403943}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'ConfigSpace.hyperparameters.CategoricalHyperparameter' and 'ConfigSpace.hyperparameters.CategoricalHyperparameter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f38c5c7f03c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_differentiable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GitRepo/TabPFN/tabpfn/scripts/model_builder.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(config, device, should_train, verbose, state_dict, epoch_callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'aggregate_k_gradients'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aggregate_k_gradients'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aggregate_k_gradients'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nlayers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bptt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bptt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10824640000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_steps'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_steps'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aggregate_k_gradients'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'ConfigSpace.hyperparameters.CategoricalHyperparameter' and 'ConfigSpace.hyperparameters.CategoricalHyperparameter'"
     ]
    }
   ],
   "source": [
    "# Setting up the configuration for the simulation of batch\n",
    "config = get_prior_config(\"causal\")\n",
    "#config = model_builder.get_mlp_prior_hyperparameters(config)\n",
    "print(config)\n",
    "# config = evaluate_hypers(config, sample_diff_hps=True)\n",
    "config = sample_differentiable(config)\n",
    "print(hyper)\n",
    "model_builder.get_model(config, device = 'cpu', should_train=True, verbose=True, state_dict=None, epoch_callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper['num_layers'] = hyper['num_layers']()\n",
    "# hyper['prior_mlp_hidden_dim'] = hyper['prior_mlp_hidden_dim']()\n",
    "# hyper['prior_mlp_dropout_prob'] = hyper['prior_mlp_dropout_prob']()\n",
    "# hyper['noise_std'] = hyper['noise_std']()\n",
    "# hyper['init_std'] = hyper['init_std']()\n",
    "# hyper['num_causes'] = hyper['num_causes']()\n",
    "# hyper['prior_mlp_dropout_prob'] = hyper['prior_mlp_dropout_prob']()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'function' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7bbb11b08034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GitRepo/TabPFN/tabpfn/priors/mlp.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(batch_size, seq_len, num_features, hyperparameters, device, num_outputs, sampling, epoch, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitRepo/TabPFN/tabpfn/priors/mlp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hyperparameters)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_causes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_mlp_hidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_mlp_hidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgenerate_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'function' and 'int'"
     ]
    }
   ],
   "source": [
    "batch = get_batch(batch_size = 1000, seq_len = 100, num_features = 100, hyperparameters = hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_config(config_type='causal', task_type='multiclass', longer=0):\n",
    "    config = get_prior_config(config_type=config_type)\n",
    "    \n",
    "    config['prior_type'], config['differentiable'], config['flexible'] = 'mlp', True, True\n",
    "    \n",
    "    model_string = ''\n",
    "    \n",
    "    config['epochs'] = 12000\n",
    "    config['recompute_attn'] = True\n",
    "\n",
    "    config['max_num_classes'] = 10\n",
    "    config['num_classes'] = uniform_int_sampler_f(2, config['max_num_classes'])\n",
    "    config['balanced'] = False\n",
    "    model_string = model_string + '_multiclass'\n",
    "    \n",
    "    model_string = model_string + '_'+datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "    \n",
    "    return config, model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.00010443982527019839, 'dropout': 0.0, 'emsize': 512, 'batch_size': 4, 'nlayers': 12, 'num_features': 100, 'nhead': 4, 'nhid_factor': 2, 'bptt': 1152, 'eval_positions': None, 'seq_len_used': 50, 'sampling': 'normal', 'epochs': 400, 'num_steps': 128, 'verbose': False, 'mix_activations': False, 'pre_sample_causes': True, 'multiclass_type': 'rank', 'nan_prob_unknown_reason_reason_prior': 0.5, 'categorical_feature_p': 0.2, 'nan_prob_no_reason': 0.0, 'nan_prob_unknown_reason': 0.0, 'nan_prob_a_reason': 0.0, 'max_num_classes': 10, 'num_classes': <function <lambda>.<locals>.<lambda> at 0x7f8e202e5280>, 'noise_type': 'Gaussian', 'balanced': False, 'normalize_to_ranking': False, 'set_value_to_nan': 0.1, 'normalize_by_used_features': True, 'num_features_used': {'uniform_int_sampler_f(3,max_features)': <function <lambda>.<locals>.<lambda> at 0x7f8e202e51f0>}, 'num_categorical_features_sampler_a': -1.0, 'differentiable_hyperparameters': {'prior_bag_exp_weights_1': {'distribution': 'uniform', 'min': 2.0, 'max': 10.0}, 'num_layers': {'distribution': 'meta_gamma', 'max_alpha': 2, 'max_scale': 3, 'round': True, 'lower_bound': 2}, 'prior_mlp_hidden_dim': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 4}, 'prior_mlp_dropout_prob': {'distribution': 'meta_beta', 'scale': 0.6, 'min': 0.1, 'max': 5.0}, 'noise_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 0.3, 'min_mean': 0.0001, 'round': False, 'lower_bound': 0.0}, 'init_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 0.01, 'round': False, 'lower_bound': 0.0}, 'num_causes': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 7, 'round': True, 'lower_bound': 2}, 'is_causal': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'pre_sample_weights': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'y_is_effect': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'prior_mlp_activations': {'distribution': 'meta_choice_mixed', 'choice_values': [<class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.ReLU'>]}, 'block_wise_dropout': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'sort_features': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'in_clique': {'distribution': 'meta_choice', 'choice_values': [True, False]}, 'outputscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0}, 'noise': {'distribution': 'meta_choice', 'choice_values': [1e-05, 0.0001, 0.01]}}, 'prior_type': 'mlp', 'differentiable': True, 'flexible': True, 'recompute_attn': True, 'bptt_extra_samples': None, 'output_multiclass_ordered_p': 0.0, 'multiclass_loss_type': 'nono', 'normalize_with_sqrt': False, 'new_mlp_per_example': True, 'prior_mlp_scale_weights_sqrt': True, 'batch_size_per_gp_sample': None, 'normalize_ignore_label_too': False, 'differentiable_hps_as_style': False, 'max_eval_pos': 1000, 'random_feature_rotation': True, 'rotate_normalized_labels': True, 'canonical_y_encoder': False, 'aggregate_k_gradients': 8, 'total_available_time_in_s': None, 'train_mixed_precision': True, 'efficient_eval_masking': True}\n"
     ]
    }
   ],
   "source": [
    "config, model_string = reload_config(longer=1)\n",
    "\n",
    "config['bptt_extra_samples'] = None\n",
    "\n",
    "# diff\n",
    "config['output_multiclass_ordered_p'] = 0.\n",
    "del config['differentiable_hyperparameters']['output_multiclass_ordered_p']\n",
    "\n",
    "config['multiclass_type'] = 'rank'\n",
    "del config['differentiable_hyperparameters']['multiclass_type']\n",
    "\n",
    "config['sampling'] = 'normal' # vielleicht schlecht?\n",
    "del config['differentiable_hyperparameters']['sampling']\n",
    "\n",
    "config['pre_sample_causes'] = True\n",
    "# end diff\n",
    "\n",
    "config['multiclass_loss_type'] = 'nono' # 'compatible'\n",
    "config['normalize_to_ranking'] = False # False\n",
    "\n",
    "config['categorical_feature_p'] = .2 # diff: .0\n",
    "\n",
    "# turn this back on in a random search!?\n",
    "config['nan_prob_no_reason'] = .0\n",
    "config['nan_prob_unknown_reason'] = .0 # diff: .0\n",
    "config['set_value_to_nan'] = .1 # diff: 1.\n",
    "\n",
    "config['normalize_with_sqrt'] = False\n",
    "\n",
    "config['new_mlp_per_example'] = True\n",
    "config['prior_mlp_scale_weights_sqrt'] = True\n",
    "config['batch_size_per_gp_sample'] = None\n",
    "\n",
    "config['normalize_ignore_label_too'] = False\n",
    "\n",
    "config['differentiable_hps_as_style'] = False\n",
    "config['max_eval_pos'] = 1000\n",
    "\n",
    "config['random_feature_rotation'] = True\n",
    "config['rotate_normalized_labels'] = True\n",
    "\n",
    "config[\"mix_activations\"] = False # False heisst eig True\n",
    "\n",
    "config['emsize'] = 512\n",
    "config['nhead'] = config['emsize'] // 128\n",
    "config['bptt'] = 1024+128\n",
    "config['canonical_y_encoder'] = False\n",
    "\n",
    "    \n",
    "config['aggregate_k_gradients'] = 8\n",
    "config['batch_size'] = 8*config['aggregate_k_gradients']\n",
    "config['num_steps'] = 1024//config['aggregate_k_gradients']\n",
    "config['epochs'] = 400\n",
    "config['total_available_time_in_s'] = None #60*60*22 # 22 hours for some safety...\n",
    "\n",
    "config['train_mixed_precision'] = True\n",
    "config['efficient_eval_masking'] = True\n",
    "\n",
    "config = evaluate_hypers(config)\n",
    "config['batch_size'] = 4\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_get_batch(model_proto, **extra_kwargs):\n",
    "    def new_get_batch(batch_size, seq_len, num_features, hyperparameters\n",
    "            , device, model_proto=model_proto\n",
    "            , **kwargs):\n",
    "        kwargs = {**extra_kwargs, **kwargs} # new args overwrite pre-specified args\n",
    "        return model_proto.get_batch(\n",
    "            batch_size=batch_size\n",
    "            , seq_len=seq_len\n",
    "            , device=device\n",
    "            , hyperparameters=hyperparameters\n",
    "            , num_features=num_features, **kwargs)\n",
    "    return new_get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pos_seq_len_sampler():\n",
    "    single_eval_pos = single_eval_pos_gen()\n",
    "    if bptt_extra_samples:\n",
    "        return single_eval_pos, single_eval_pos + bptt_extra_samples\n",
    "    else:\n",
    "        return single_eval_pos, bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.00010443982527019839, 'dropout': 0.0, 'emsize': 512, 'batch_size': 4, 'nlayers': 12, 'num_features': 100, 'nhead': 4, 'nhid_factor': 2, 'bptt': 1152, 'eval_positions': None, 'seq_len_used': 50, 'sampling': 'normal', 'epochs': 400, 'num_steps': 128, 'verbose': False, 'mix_activations': False, 'pre_sample_causes': True, 'multiclass_type': 'rank', 'nan_prob_unknown_reason_reason_prior': 0.5, 'categorical_feature_p': 0.2, 'nan_prob_no_reason': 0.0, 'nan_prob_unknown_reason': 0.0, 'nan_prob_a_reason': 0.0, 'max_num_classes': 10, 'num_classes': <function <lambda>.<locals>.<lambda> at 0x7f8e202e5280>, 'noise_type': 'Gaussian', 'balanced': False, 'normalize_to_ranking': False, 'set_value_to_nan': 0.1, 'normalize_by_used_features': True, 'num_features_used': {'uniform_int_sampler_f(3,max_features)': <function <lambda>.<locals>.<lambda> at 0x7f8e202e51f0>}, 'num_categorical_features_sampler_a': -1.0, 'differentiable_hyperparameters': {'prior_bag_exp_weights_1': {'distribution': 'uniform', 'min': 2.0, 'max': 10.0, 'sample': prior_bag_exp_weights_1, Type: UniformFloat, Range: [2.0, 10.0], Default: 6.0}, 'num_layers': {'distribution': 'meta_gamma', 'max_alpha': 2, 'max_scale': 3, 'round': True, 'lower_bound': 2, 'alpha': num_layers_k, Type: UniformFloat, Range: [0.0, 0.6931471805599453], Default: 0.3465735903, 'scale': num_layers_b, Type: UniformFloat, Range: [0.0, 3.0], Default: 1.5}, 'prior_mlp_hidden_dim': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 100, 'round': True, 'lower_bound': 4, 'alpha': prior_mlp_hidden_dim_k, Type: UniformFloat, Range: [0.0, 1.0986122886681098], Default: 0.5493061443, 'scale': prior_mlp_hidden_dim_b, Type: UniformFloat, Range: [0.0, 100.0], Default: 50.0}, 'prior_mlp_dropout_prob': {'distribution': 'meta_beta', 'scale': 0.6, 'min': 0.1, 'max': 5.0, 'k': prior_mlp_dropout_prob_k, Type: UniformFloat, Range: [0.1, 5.0], Default: 2.55, 'b': prior_mlp_dropout_prob_b, Type: UniformFloat, Range: [0.1, 5.0], Default: 2.55}, 'noise_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 0.3, 'min_mean': 0.0001, 'round': False, 'lower_bound': 0.0, 'log_mean': noise_std_log_mean, Type: UniformFloat, Range: [-9.210340371976182, -1.2039728043259361], Default: -5.2071565882, 'log_std': noise_std_log_std, Type: UniformFloat, Range: [-2.3025850929940455, 0.0], Default: -1.1512925465}, 'init_std': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 0.01, 'round': False, 'lower_bound': 0.0, 'log_mean': init_std_log_mean, Type: UniformFloat, Range: [-4.605170185988091, 2.302585092994046], Default: -1.1512925465, 'log_std': init_std_log_std, Type: UniformFloat, Range: [-2.3025850929940455, 0.0], Default: -1.1512925465}, 'num_causes': {'distribution': 'meta_gamma', 'max_alpha': 3, 'max_scale': 7, 'round': True, 'lower_bound': 2, 'alpha': num_causes_k, Type: UniformFloat, Range: [0.0, 1.0986122886681098], Default: 0.5493061443, 'scale': num_causes_b, Type: UniformFloat, Range: [0.0, 7.0], Default: 3.5}, 'is_causal': {'distribution': 'meta_choice', 'choice_values': [True, False], 'choice_1_weight': is_causalchoice_1_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0}, 'pre_sample_weights': {'distribution': 'meta_choice', 'choice_values': [True, False], 'choice_1_weight': pre_sample_weightschoice_1_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0}, 'y_is_effect': {'distribution': 'meta_choice', 'choice_values': [True, False], 'choice_1_weight': y_is_effectchoice_1_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0}, 'prior_mlp_activations': {'distribution': 'meta_choice_mixed', 'choice_values': [<class 'torch.nn.modules.activation.Tanh'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.ReLU'>], 'choice_1_weight': prior_mlp_activationschoice_1_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0, 'choice_2_weight': prior_mlp_activationschoice_2_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0}, 'block_wise_dropout': {'distribution': 'meta_choice', 'choice_values': [True, False], 'choice_1_weight': block_wise_dropoutchoice_1_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0}, 'sort_features': {'distribution': 'meta_choice', 'choice_values': [True, False], 'choice_1_weight': sort_featureschoice_1_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0}, 'in_clique': {'distribution': 'meta_choice', 'choice_values': [True, False], 'choice_1_weight': in_cliquechoice_1_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0}, 'outputscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0, 'log_mean': outputscale_log_mean, Type: UniformFloat, Range: [-11.512925464970229, 2.302585092994046], Default: -4.605170186, 'log_std': outputscale_log_std, Type: UniformFloat, Range: [-2.3025850929940455, 0.0], Default: -1.1512925465}, 'lengthscale': {'distribution': 'meta_trunc_norm_log_scaled', 'max_mean': 10.0, 'min_mean': 1e-05, 'round': False, 'lower_bound': 0, 'log_mean': lengthscale_log_mean, Type: UniformFloat, Range: [-11.512925464970229, 2.302585092994046], Default: -4.605170186, 'log_std': lengthscale_log_std, Type: UniformFloat, Range: [-2.3025850929940455, 0.0], Default: -1.1512925465}, 'noise': {'distribution': 'meta_choice', 'choice_values': [1e-05, 0.0001, 0.01], 'choice_1_weight': noisechoice_1_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0, 'choice_2_weight': noisechoice_2_weight, Type: UniformFloat, Range: [-3.0, 5.0], Default: 1.0}}, 'prior_type': 'mlp', 'differentiable': True, 'flexible': True, 'recompute_attn': True, 'bptt_extra_samples': None, 'output_multiclass_ordered_p': 0.0, 'multiclass_loss_type': 'nono', 'normalize_with_sqrt': False, 'new_mlp_per_example': True, 'prior_mlp_scale_weights_sqrt': True, 'batch_size_per_gp_sample': None, 'normalize_ignore_label_too': False, 'differentiable_hps_as_style': False, 'max_eval_pos': 1000, 'random_feature_rotation': True, 'rotate_normalized_labels': True, 'canonical_y_encoder': False, 'aggregate_k_gradients': 8, 'total_available_time_in_s': None, 'train_mixed_precision': True, 'efficient_eval_masking': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = replace_differentiable_distributions(config)\n",
    "\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.00010443982527019839, 'dropout': 0.0, 'emsize': 512, 'batch_size': 1, 'nlayers': 12, 'num_features': 100, 'nhead': 4, 'nhid_factor': 2, 'bptt': 1152, 'eval_positions': None, 'seq_len_used': 50, 'sampling': 'normal', 'epochs': 400, 'num_steps': 1024, 'verbose': False, 'mix_activations': False, 'pre_sample_causes': True, 'multiclass_type': 'rank', 'nan_prob_unknown_reason_reason_prior': 0.5, 'categorical_feature_p': 0.2, 'nan_prob_no_reason': 0.0, 'nan_prob_unknown_reason': 0.0, 'nan_prob_a_reason': 0.0, 'max_num_classes': 10, 'num_classes': <function <lambda>.<locals>.<lambda> at 0x7f8e202e5280>, 'noise_type': 'Gaussian', 'balanced': False, 'normalize_to_ranking': False, 'set_value_to_nan': 0.1, 'normalize_by_used_features': True, 'num_features_used': <function <lambda>.<locals>.<lambda> at 0x7f8e202e51f0>, 'num_categorical_features_sampler_a': -1.0, 'differentiable_hyperparameters': {'distribution': 'uniform', 'min': 2.0, 'max': 10.0, 'sample': prior_bag_exp_weights_1, Type: UniformFloat, Range: [2.0, 10.0], Default: 6.0}, 'prior_type': 'mlp', 'differentiable': True, 'flexible': True, 'recompute_attn': True, 'bptt_extra_samples': None, 'output_multiclass_ordered_p': 0.0, 'multiclass_loss_type': 'nono', 'normalize_with_sqrt': False, 'new_mlp_per_example': True, 'prior_mlp_scale_weights_sqrt': True, 'batch_size_per_gp_sample': None, 'normalize_ignore_label_too': False, 'differentiable_hps_as_style': False, 'max_eval_pos': 1000, 'random_feature_rotation': True, 'rotate_normalized_labels': True, 'canonical_y_encoder': False, 'aggregate_k_gradients': 8, 'total_available_time_in_s': None, 'train_mixed_precision': True, 'efficient_eval_masking': True}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prior_mlp_activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-3849906d4c58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_pos_seq_len_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_prior_kwargs_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GitRepo/TabPFN/tabpfn/priors/utils.py\u001b[0m in \u001b[0;36mget_test_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_test_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# does not increase epoch_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitRepo/TabPFN/tabpfn/priors/utils.py\u001b[0m in \u001b[0;36mgbm\u001b[0;34m(eval_pos_seq_len_sampler, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'dynamic_batch_size'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dynamic_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dynamic_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_len_maximum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dynamic_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dynamic_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_method_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'single_eval_pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitRepo/TabPFN/tabpfn/priors/mlp.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(batch_size, seq_len, num_features, hyperparameters, device, num_outputs, sampling, epoch, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mix_activations'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mix_activations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_mlp_activations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_mlp_activations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prior_mlp_activations'"
     ]
    }
   ],
   "source": [
    "if 'aggregate_k_gradients' not in config or config['aggregate_k_gradients'] is None:\n",
    "    config['aggregate_k_gradients'] = math.ceil(config['batch_size'] * ((config['nlayers'] * config['emsize'] * config['bptt'] * config['bptt']) / 10824640000))\n",
    "\n",
    "config['num_steps'] = math.ceil(config['num_steps'] * config['aggregate_k_gradients'])\n",
    "config['batch_size'] = math.ceil(config['batch_size'] / config['aggregate_k_gradients'])\n",
    "config['recompute_attn'] = config['recompute_attn'] if 'recompute_attn' in config else False\n",
    "single_eval_pos_gen =  lambda: 100, 150\n",
    "\n",
    "\n",
    "\n",
    "kwargs = model_builder.get_mlp_prior_hyperparameters(config)\n",
    "\n",
    "print(kwargs)\n",
    "extra_prior_kwargs_dict={\n",
    "            'num_steps': config['num_steps'],\n",
    "            'num_features': config['num_features']\n",
    "            , 'hyperparameters': kwargs\n",
    "            #, 'dynamic_batch_size': 1 if ('num_global_att_tokens' in config and config['num_global_att_tokens']) else 2\n",
    "            , 'batch_size_per_gp_sample': config.get('batch_size_per_gp_sample', None)\n",
    "        }\n",
    "\n",
    "def sampler():\n",
    "    return 100, 150\n",
    "mlp.DataLoader(batch_size = 1000, eval_pos_seq_len_sampler = sampler, **extra_prior_kwargs_dict).get_test_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(size = (3, 4))\n",
    "b = torch.rand(size = (3, 4))\n",
    "c = torch.cat([a, b], 0)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8895],\n",
       "         [0.7663],\n",
       "         [0.8216],\n",
       "         [0.6013]],\n",
       "\n",
       "        [[0.5865],\n",
       "         [0.7375],\n",
       "         [0.4444],\n",
       "         [0.6302]],\n",
       "\n",
       "        [[0.2148],\n",
       "         [0.2099],\n",
       "         [0.2082],\n",
       "         [0.0524]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6d6d9c67bd866f2863d36ba190941b1108b5328bc23ef86323e39400fe2bc0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
